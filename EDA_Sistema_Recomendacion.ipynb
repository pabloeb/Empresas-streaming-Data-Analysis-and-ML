{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SISTEMA DE RECOMENDACION:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from surprise.model_selection import train_test_split, GridSearchCV,train_test_split\n",
    "from surprise import Dataset, Reader, SVD,KNNWithMeans,NMF\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>rating</th>\n",
       "      <th>movieid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>as680</td>\n",
       "      <td>The English Civil War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>583</td>\n",
       "      <td>4.5</td>\n",
       "      <td>as680</td>\n",
       "      <td>The English Civil War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>765</td>\n",
       "      <td>5.0</td>\n",
       "      <td>as680</td>\n",
       "      <td>The English Civil War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2116</td>\n",
       "      <td>3.0</td>\n",
       "      <td>as680</td>\n",
       "      <td>The English Civil War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>as680</td>\n",
       "      <td>The English Civil War</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  rating movieid                  title\n",
       "0       1     1.0   as680  The English Civil War\n",
       "1     583     4.5   as680  The English Civil War\n",
       "2     765     5.0   as680  The English Civil War\n",
       "3    2116     3.0   as680  The English Civil War\n",
       "4    2143     3.0   as680  The English Civil War"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_usuarios = pd.read_csv(\"df_ML.csv\")\n",
    "df_usuarios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10995634, 4)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_usuarios.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>rating</th>\n",
       "      <th>movieid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6445</td>\n",
       "      <td>The English Civil War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>583</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6445</td>\n",
       "      <td>The English Civil War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>765</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6445</td>\n",
       "      <td>The English Civil War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2116</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6445</td>\n",
       "      <td>The English Civil War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6445</td>\n",
       "      <td>The English Civil War</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  rating  movieid                  title\n",
       "0       1     1.0     6445  The English Civil War\n",
       "1     583     4.5     6445  The English Civil War\n",
       "2     765     5.0     6445  The English Civil War\n",
       "3    2116     3.0     6445  The English Civil War\n",
       "4    2143     3.0     6445  The English Civil War"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Paso la columna movieid a un valor categórico numérico\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_usuarios['movieid'] = le.fit_transform(df_usuarios['movieid'])\n",
    "df_usuarios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    10995634\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_usuarios.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22998"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cantidad de películas totales en el dataframe\n",
    "df_usuarios[\"movieid\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usuarios_eda = df_usuarios.drop(columns=[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usuarios_eda.to_pickle(\"https://www.dropbox.com/s/up7v9kce3son55b/dataframe_EDA.pkl?dl=1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML PROCESS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `MODELO CON ALGORITMO SVD (Singular Value Decomposition):`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " <div style=\"width: 120px; height: 35px; background-color: #E2E2E2; border-radius: 10px; display: flex; justify-content: center; align-items: center;\">\n",
    "    <span style=\"font-size: 18px; font-weight: bold; color: #000000;\">Información</span>\n",
    "</div>El algoritmo SVD de la librería surprise utiliza el enfoque de filtrado colaborativo (user-user) para hacer recomendaciones personalizadas para un usuario dado. En particular, utiliza el algoritmo SVD para factorizar la matriz de calificaciones de los usuarios (que tiene filas correspondientes a los usuarios, columnas correspondientes a las películas y elementos correspondientes a las calificaciones de los usuarios para esas películas) en dos matrices de factores latentes: una matriz de usuarios y una matriz de películas. Luego, utiliza estas matrices para hacer predicciones de calificación para películas que el usuario aún no ha visto.\n",
    "\n",
    "Para encontrar a los usuarios más similares al usuario dado, el algoritmo calcula las similitudes de coseno entre el vector de preferencias del usuario dado (es decir, sus calificaciones para todas las películas) y los vectores de preferencias de todos los demás usuarios en el conjunto de datos. Luego, se selecciona un subconjunto de usuarios con las similitudes más altas y se utiliza la información de calificación de estas películas para hacer predicciones para el usuario dado.\n",
    "\n",
    "En resumen, el algoritmo utiliza información sobre las películas vistas por el usuario dado (a través de la matriz de calificaciones) para encontrar a los usuarios más similares a él y hacer predicciones de calificación personalizadas para las películas no vistas por ese usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reader = Reader(rating_scale=(1, 5))  # Fuerzo que la escala de cálculo de la estimación de salida sea de 1 a 5.Si no, el software podría adoptar otro criterio\n",
    "\n",
    "data = Dataset.load_from_df(df_usuarios[['userid', 'movieid', 'rating']], reader)\n",
    "\n",
    "# Separamos nuestros datos\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "model = SVD()\n",
    "\n",
    "#Entrenamos\n",
    "model.fit(trainset)\n",
    "\n",
    "# Predecimos\n",
    "predictions = model.test(testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 100        item: 123        r_ui = None   est = 3.39   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# Elegimos un usuario y una película para hacer una recomendación\n",
    "model.predict(100,123)\n",
    "\n",
    "\n",
    "# Tomaremos un usuario para hacerle una recomendación\n",
    "print(model.predict(100,123))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretación de resultados:  \n",
    "- uid : es el número de usuario para el cual se realizó la predicción.\n",
    "- iid : este es id de la película seleccionada para realizar la predicción.\n",
    "- est : este es el valor promedio estimado que un grupo de usuarios con características similares al usuario seleccionadoa califica la película.\n",
    "- {'was_impossible': False}: el parámetro False nos indica que la predicción se pudo hacer correctamente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METRICAS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0022\n",
      "MSE: 1.0044\n",
      "RMSE: 1.002206964181792\n",
      "MSE: 1.0044187990544833\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Es importante tener una métrica de bondad de ajuste (coef. determinación r2) y una métrica de error.La librería surprise no trae la métrica r2 por lo tanto hay que calcularla.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mse = accuracy.mse(predictions)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando Optimización de parámetros con GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# Definir los parámetros para el modelo SVD y crear un objeto GridSearchCV para encontrar los mejores parámetros a través de la validación cruzada:\\nparam_grid = {'n_factors': [50, 100, 150],'n_epochs': [20, 30, 40]}   \\n\\n# crear un objeto GridSearchCV           \\ngs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\\n\\ngs.fit(data)\\n\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Definir los parámetros para el modelo SVD y crear un objeto GridSearchCV para encontrar los mejores parámetros a través de la validación cruzada:\n",
    "param_grid = {'n_factors': [50, 100, 150],'n_epochs': [20, 30, 40]}   \n",
    "\n",
    "# crear un objeto GridSearchCV           \n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 120px; height: 35px; background-color: #E2E2E2; border-radius: 10px; display: flex; justify-content: center; align-items: center;\">\n",
    "    <span style=\"font-size: 18px; font-weight: bold; color: #000000;\">Información</span>\n",
    "</div>Parámetros de ajuste seleccionados en la grilla de Gridsearch para optimizar el modelo SVD:\n",
    "\n",
    "- n_factors: Número de factores latentes que se utilizan para representar a los usuarios y elementos en la matriz de factores latentes. El valor predeterminado es 100. Si el valor es demasiado bajo, el modelo puede no capturar todas las relaciones importantes entre los usuarios y los elementos en los datos. Si el valor es demasiado alto, el modelo puede sobreajustarse a los datos y no generalizar bien a nuevos datos.\n",
    "\n",
    "- n_epochs: Número de épocas (iteraciones) para entrenar el modelo. El valor predeterminado es 20. Si el valor es demasiado bajo, el modelo puede no converger a una solución óptima. Si el valor es demasiado alto, el modelo puede sobreajustarse a los datos y no generalizar bien a nuevos datos.\n",
    "\n",
    "- lr_all: Tasa de aprendizaje para todos los parámetros del modelo. El valor predeterminado es 0.005. Controla la magnitud de las actualizaciones de parámetros durante el entrenamiento del modelo. Si el valor es demasiado alto, el modelo puede diverger y no converger a una solución óptima. Si el valor es demasiado bajo, el modelo puede tardar más en converger a una solución óptima.\n",
    "\n",
    "- reg_all: Tasa de regularización para todos los parámetros del modelo. El valor predeterminado es 0.02. Controla la magnitud de los pesos de regularización aplicados a los parámetros del modelo durante el entrenamiento. La regularización ayuda a prevenir el sobreajuste del modelo. Si el valor es demasiado alto, el modelo puede ser demasiado restrictivo y no capturar todas las relaciones importantes en los datos. Si el valor es demasiado bajo, el modelo puede sobreajustarse a los datos y no generalizar bien a nuevos datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Métricas con GridSearch:\\n\\nbest_rmse = gs.best_score[\\'rmse\\']\\nprint(\"best_rmse: \",best_rmse)\\n\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Métricas con GridSearch:\n",
    "\n",
    "best_rmse = gs.best_score['rmse']\n",
    "print(\"best_rmse: \",best_rmse)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### `MODELO CON ALGORITMO KNNWithMEANS :`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nreader = Reader(rating_scale=(1, 5))  # Fuerzo que la escala de cálculo de la estimación de salida sea de 1 a 5.Si no, el software podría adoptar otro criterio\\n\\ndata = Dataset.load_from_df(df_usuarios[['userid', 'movieid', 'rating']], reader)\\n\\n# Separamos nuestros datos\\ntrainset, testset = train_test_split(data, test_size=.25)\\n\\nmodel_1 = KNNWithMeans()\\n\\n#Entrenamos\\nmodel_1.fit(trainset)\\n\\n# Predecimos\\npredictions_1 = model_1.test(testset)\\n# Elegimos un usuario y una película para hacer una recomendación\\nmodel_1.predict(146200,2255)\\n# Tomaremos un usuario para hacerle una recomendación\\nprint(model_1.predict(146200,2255))\\n\\n\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))  # Fuerzo que la escala de cálculo de la estimación de salida sea de 1 a 5.Si no, el software podría adoptar otro criterio\n",
    "\n",
    "data = Dataset.load_from_df(df_usuarios[['userid', 'movieid', 'rating']], reader)\n",
    "\n",
    "# Separamos nuestros datos\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "model_1 = KNNWithMeans()\n",
    "\n",
    "#Entrenamos\n",
    "model_1.fit(trainset)\n",
    "\n",
    "# Predecimos\n",
    "predictions_1 = model_1.test(testset)\n",
    "# Elegimos un usuario y una película para hacer una recomendación\n",
    "model_1.predict(146200,2255)\n",
    "# Tomaremos un usuario para hacerle una recomendación\n",
    "print(model_1.predict(146200,2255))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 120px; height: 35px; background-color: #E2E2E2; border-radius: 10px; display: flex; justify-content: center; align-items: center;\">\n",
    "    <span style=\"font-size: 18px; font-weight: bold; color: #000000;\">Información</span>\n",
    "</div> Tira error pof falta de capacidad de procesamiento y memoria para procesar una matriz (1000000 x 1000000)\n",
    "\n",
    "En general, el algoritmo kNNwithMeans y el algoritmo SVD tienen requerimientos de recursos similares, ya que ambos deben procesar todo el conjunto de datos y realizar cálculos intensivos.\n",
    "\n",
    "Sin embargo, hay algunos factores que pueden influir en los requerimientos de recursos de cada algoritmo en diferentes situaciones. Por ejemplo:\n",
    "\n",
    "Tamaño del conjunto de datos: Si el conjunto de datos es muy grande, kNNwithMeans podría requerir más recursos ya que necesita calcular las similitudes entre todas las parejas de usuarios/items, lo que implica comparar cada usuario/item con todos los demás en el conjunto de datos. En cambio, SVD utiliza descomposición de matriz para reducir la complejidad del cálculo de las recomendaciones, lo que lo hace más escalable.\n",
    "\n",
    "Densidad del conjunto de datos: Si el conjunto de datos es muy denso (es decir, la mayoría de las entradas están completas), SVD podría requerir más recursos ya que necesita realizar cálculos en todas las entradas, mientras que kNNwithMeans solo necesita calcular las similitudes entre los elementos que tienen entradas en común.\n",
    "\n",
    "Parámetros del modelo: Los parámetros de cada modelo también pueden influir en los requerimientos de recursos. Por ejemplo, el número de factores latentes en SVD puede afectar la complejidad de los cálculos, mientras que el número de vecinos k en kNNwithMeans puede influir en la cantidad de cálculos necesarios para calcular las similitudes.\n",
    "\n",
    "En resumen, kNNwithMeans y SVD tienen requerimientos de recursos similares en general, pero el algoritmo más adecuado dependerá del tamaño y la densidad del conjunto de datos, así como de los parámetros específicos del modelo. Es importante tener en cuenta estos factores al elegir el algoritmo adecuado para un problema de recomendación específico."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `MODELO CON ALGORITMO NMF:`  \n",
    "\n",
    "<div style=\"width: 120px; height: 35px; background-color: #E2E2E2; border-radius: 10px; display: flex; justify-content: center; align-items: center;\">\n",
    "    <span style=\"font-size: 18px; font-weight: bold; color: #000000;\">Información</span>\n",
    "</div> En Surprise, NMF significa \"Non-negative Matrix Factorization\" (Factorización de matriz no negativa). Es un algoritmo de factorización de matrices que se utiliza para reducir la dimensionalidad de un conjunto de datos y para encontrar patrones latentes en los datos. En el contexto de la recomendación de películas, se utiliza para descomponer la matriz de valoraciones de los usuarios y las películas en dos matrices más pequeñas que representan características latentes de las películas y preferencias latentes de los usuarios. Luego, estas dos matrices se multiplican para generar una aproximación de la matriz original de valoraciones, que se utiliza para hacer recomendaciones a los usuarios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nreader = Reader(rating_scale=(1, 5))  # Fuerzo que la escala de cálculo de la estimación de salida sea de 1 a 5.Si no, el software podría adoptar otro criterio\\n\\ndata = Dataset.load_from_df(df_usuarios[['userid', 'movieid', 'rating']], reader)\\n\\n# Separamos nuestros datos\\ntrainset, testset = train_test_split(data, test_size=.25)\\n\\n# Crear una instancia del modelo NMF\\nmodel_2 = NMF()\\n\\n# Entrenar el modelo con el conjunto de entrenamiento\\nmodel_2.fit(trainset)\\n\\n# Hacer predicciones para el conjunto de prueba\\npredictions_2 = model_2.test(testset)\\n\\n# Calcular el error RMSE y MAE\\nrmse = accuracy.rmse(predictions_2)\\nmse = accuracy.mse(predictions_2)\\n\\nr2 = 1 - mse / ((df_usuarios['rating'] - df_usuarios['rating'].mean())**2).mean()  \\n\\n# Hacer una predicción para un usuario y una película específicos\\nuid = 100  # ID del usuario\\niid = 123  # ID de la película\\nmodel_2.predict(uid, iid)\\nprint(model_2.predict(uid, iid))\\n\\n\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El modelo SVD optimizado es más eficiente.Se anula la ejecución de NMF porque esmuy lenta la ejecucuión de todo el código del archivo\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))  # Fuerzo que la escala de cálculo de la estimación de salida sea de 1 a 5.Si no, el software podría adoptar otro criterio\n",
    "\n",
    "data = Dataset.load_from_df(df_usuarios[['userid', 'movieid', 'rating']], reader)\n",
    "\n",
    "# Separamos nuestros datos\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# Crear una instancia del modelo NMF\n",
    "model_2 = NMF()\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "model_2.fit(trainset)\n",
    "\n",
    "# Hacer predicciones para el conjunto de prueba\n",
    "predictions_2 = model_2.test(testset)\n",
    "\n",
    "# Calcular el error RMSE y MAE\n",
    "rmse = accuracy.rmse(predictions_2)\n",
    "mse = accuracy.mse(predictions_2)\n",
    "\n",
    "r2 = 1 - mse / ((df_usuarios['rating'] - df_usuarios['rating'].mean())**2).mean()  \n",
    "\n",
    "# Hacer una predicción para un usuario y una película específicos\n",
    "uid = 100  # ID del usuario\n",
    "iid = 123  # ID de la película\n",
    "model_2.predict(uid, iid)\n",
    "print(model_2.predict(uid, iid))\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nprint(\"RMSE:\", rmse)\\nprint(\"MSE:\", mse)\\nprint(\"R2:\", r2)\\n\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando Optimización de parámetros con GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Definir los parámetros para el modelo NMF y crear un objeto GridSearchCV para encontrar los mejores parámetros a través de la validación cruzada:\\nparam_grid = {'n_factors': [50, 100, 150], 'n_epochs': [20, 30, 40]}\\n\\n# crear un objeto GridSearchCV           \\ngs1 = GridSearchCV(NMF, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\\n\\n# Ajustar el modelo\\ngs1.fit(data)\\n\\n\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Definir los parámetros para el modelo NMF y crear un objeto GridSearchCV para encontrar los mejores parámetros a través de la validación cruzada:\n",
    "param_grid = {'n_factors': [50, 100, 150], 'n_epochs': [20, 30, 40]}\n",
    "\n",
    "# crear un objeto GridSearchCV           \n",
    "gs1 = GridSearchCV(NMF, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# Ajustar el modelo\n",
    "gs1.fit(data)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#Métricas con Gridsearch\\nbest_rmse_1 = gs1.best_score[\\'rmse\\']\\nprint(\"best_rmse: \",best_rmse_1)\\n\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "#Métricas con Gridsearch\n",
    "best_rmse_1 = gs1.best_score['rmse']\n",
    "print(\"best_rmse: \",best_rmse_1)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se selecciona por perfomance el modelo SVD optimizado por GridSearch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se guarda el modelo en una librería especializda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 120px; height: 35px; background-color: #E2E2E2; border-radius: 10px; display: flex; justify-content: center; align-items: center;\">\n",
    "    <span style=\"font-size: 18px; font-weight: bold; color: #000000;\">Información</span>\n",
    "</div> Tanto Joblib como Pickle son librerías de Python que se utilizan para guardar modelos de machine learning entrenados y otros objetos de Python. Ambas librerías son útiles para serializar y deserializar objetos de Python, lo que permite guardar y cargar modelos de forma rápida y sencilla.\n",
    "\n",
    "Sin embargo, hay algunas diferencias entre Joblib y Pickle que pueden afectar la elección de una u otra para guardar modelos de machine learning entrenados:\n",
    "\n",
    "Pickle es una librería estándar de Python, lo que significa que ya está instalada en la mayoría de las distribuciones de Python. Por otro lado, Joblib es una librería externa que debe ser instalada por separado.\n",
    "\n",
    "Pickle es una librería muy versátil que puede manejar la mayoría de los tipos de objetos de Python, mientras que Joblib está especialmente diseñada para serializar y deserializar objetos grandes y complejos, como los modelos de machine learning.\n",
    "\n",
    "Pickle puede ser más lento que Joblib al serializar objetos grandes, ya que utiliza un protocolo de serialización basado en texto. Joblib, por otro lado, utiliza un protocolo de serialización binario que puede ser más rápido.\n",
    "\n",
    "En general, ambos Joblib y Pickle son buenas opciones para guardar modelos de machine learning entrenados. Pickle es más versátil y ya está instalado en Python, mientras que Joblib está optimizado para manejar objetos grandes y complejos, como los modelos de machine learning. La elección entre las dos librerías dependerá del tamaño y complejidad del modelo, así como de las preferencias personales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelo_svd.joblib']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Guardar(exporta) el modelo  SVD en un archivo llamado \"modelo_svd.joblib\"\n",
    "dump(model, 'modelo_svd.joblib')\n",
    "\n",
    "#El archivo modelo_svd.joblib que alimenta a la consola de Gradio está en Dropbox\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streaming_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
